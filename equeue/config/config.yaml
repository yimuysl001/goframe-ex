# 应用名称
appName: "程序设置"


# 统一默认日志配置
defaultLogger: &defaultLogger
  level: "all"
  flags: 42
  file: "{Y-m-d}.log"                     # 日志文件格式。默认为"{Y-m-d}.log"
  stdoutColorDisabled: false              # 关闭终端的颜色打印。默认开启
  writerColorEnable: false                # 日志文件是否带上颜色。默认false，表示不带颜色
  rotateExpire: "7d"                      # 日志保留天数
  rotateBackupLimit: 15                    # 最大备份数量
  rotateBackupCompress: 9                 # 日志文件压缩级别，0-9,9最高
  rotateCheckInterval:   "1h"

# 日志配置
logger:
  # 全局日志：g.Log()
  path: "logs/logger"                       # 日志文件路径。默认为空，表示关闭，仅输出到终端
  <<: *defaultLogger
  # 定时任务：g.Log("cron")
  trace:
    path: "logs/trace"                       # 日志文件路径。默认为空，表示关闭，仅输出到终端
    <<: *defaultLogger
  cron:
    path: "logs/cron"                       # 日志文件路径。默认为空，表示关闭，仅输出到终端
    <<: *defaultLogger
  # 消息队列：g.Log("cron")
  queue:
    path: "logs/queue"                      # 日志文件路径。默认为空，表示关闭，仅输出到终端
    <<: *defaultLogger
  # tcp服务器：g.Log("tcpServer")
  tcpServer:
    path: "logs/tcpServer"                  # 日志文件路径。默认为空，表示关闭，仅输出到终端
    <<: *defaultLogger
  # tcp客户端：g.Log("tcpClient")
  tcpClient:
    path: "logs/tcpClient"                  # 日志文件路径。默认为空，表示关闭，仅输出到终端
    <<: *defaultLogger






#消息队列
equeue:
#  switch: true                                        # 队列开关，可选：true|false，默认为true
#  driver: "redis"                                      # 队列驱动，可选：disk|redis|rocketmq|kafka，默认为disk
#  retry: 2                                            # 重试次数，仅rocketmq支持
#  groupName: "ptjksj"                                  # mq群组名称
  #磁盘队列
  disk:
    driver: "disk"
    retry: 2                                            # 重试次数，仅rocketmq支持
    groupName: "ptjksj"
    path: "storage/diskqueue"                       # 数据存放路径
    batchSize: 100                                    # 每100条消息同步一次，batchSize和batchTime满足其一就会同步一次
    batchTime: 1                                      # 每1秒消息同步一次
    segmentSize: 10485760                             # 每个topic分片数据文件最大字节，默认10M
    segmentLimit: 3000                                # 每个topic最大分片数据文件数量，超出部分将会丢弃
  redis:
    driver: "redis"
    name: "default"
    groupName: "test"
    timeout: 300
  nats:
    driver: "nats"
    address:
      - "192.168.200.26:4222"
    userName: "nats"
    password: "PTJK123qwe,.26"
    groupName: "TESTDATA"
    name: "etest"
  #redis，默认使用全局redis运行队列
#  redis:
#    timeout: 0                                        # 队列超时时间以秒为单位，0表示永不超时。如果队列在设定的超时时间内没有被消费，则会被销毁
#  rocketmq:
#    address: "127.0.0.1:9876"                         # broker地址+端口
#    logLevel: "all"                                   # 系统日志级别，可选：all|close|debug|info|warn|error|fatal
#  kafka:
#    address: "127.0.0.1:9092"                         # kafka地址+端口
#    version: "2.0.0.0"                                # kafka专属配置，默认2.0.0.0
#    randClient: true                                  # 开启随机生成clientID，可以实现启动多实例同时一起消费相同topic，加速消费能力的特性，默认为true
#    multiConsumer: true                               # 是否支持创建多个消费者


# Redis. 配置参考：https://goframe.org/pages/viewpage.action?pageId=1114217
redis:
  default:
    address: "192.168.200.26:6379"
    db: "4"
    pass: "RedisPass123qwe,."
    idleTimeout: "20"
  db:
    address: "192.168.200.26:6379"
    db: "8"
    pass: "RedisPass123qwe,."
    idleTimeout: "20"
  mq:
    address: "192.168.200.26:6379"
    db: "9"
    pass: "RedisPass123qwe,."
    idleTimeout: "20"



# Database. 配置参考：https://goframe.org/pages/viewpage.action?pageId=1114245
database:
  logger:
    level: "all"
    path: "logs/sql"
    stdout: true
  default:
    #link: "mysql:root:123qwe,.@tcp(127.0.0.1:3316)/hotgo?loc=Local&parseTime=true"
    link: "sqlite::@file(./storage/data/db/db.sqlite3)"
    extra: "journal_mode=WAL"
    debug: true
    Prefix: "hg_"
  log:
    #link: "mysql:root:123qwe,.@tcp(127.0.0.1:3316)/hotgo?loc=Local&parseTime=true"
    link: "sqlite::@file(./storage/data/db/log.sqlite3)"
    extra: "journal_mode=WAL"
    debug: true
    Prefix: "hg_"
  test:
    link: "mssql:sa:PTJK123qwe,.26@tcp(192.168.200.26:1433)/yxhis"
    #link: "sqlite3::@file(./storage/data/db/log.sqlite3)"
    extra: "journal_mode=WAL"
    debug: true
    Prefix: ""
